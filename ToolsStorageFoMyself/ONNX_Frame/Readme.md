# 此文件夹存储，关于ONNX框架下模型的操作案例

## onnx_quantization_demo（onnx模型量化）

ONNX模型的动态量化和静态量化是两种不同的模型压缩技术，主要区别体现在以下方面：

量化时机‌

动态量化在推理时实时计算量化参数（如缩放因子和零点），适用于运行时对权重和激活值进行量化。
静态量化在推理前通过校准数据集离线计算量化参数，并固化到模型中。

数据依赖‌

动态量化无需校准数据，直接根据运行时输入动态调整量化参数。
静态量化需要代表性校准数据预先计算激活值的分布范围，否则可能导致精度损失。

适用模型类型‌

动态量化对RNN、Transformer等变长输入或动态计算图的支持更好。
静态量化更适合CNN、固定输入尺寸的模型（如目标检测模型YOLOv8）。

性能与精度‌

动态量化实现简单，但推理速度提升中等（通常1.2–2倍），精度损失较小。
静态量化通过校准优化量化参数，加速效果更显著（通常2–4倍），但可能因校准数据不足导致精度下降。

部署复杂度‌

动态量化仅需调用quantize_dynamic接口即可完成。
静态量化需额外准备校准数据并调用quantize_static工具，流程更复杂。

硬件适配性‌

静态量化因参数固定，更易利用硬件专用优化（如INT8指令集）。
动态量化因实时计算参数，可能增加推理延迟，但适应性更强。
