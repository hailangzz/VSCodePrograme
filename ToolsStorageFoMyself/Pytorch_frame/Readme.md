# 此文件存储关于Pytorch框架下的模型操作

## dynamic_to_static_use_onnx.py（onnx框架，实现pt动态模型转静态模型）
    动态导出阶段保留原始模型的动态维度特性
    静态转换时通过修改ONNX proto对象固定输入维度
    验证步骤确认模型输入输出是否符合静态要求
    支持自定义固定尺寸（示例中设为640x640）
    完整工作流包含模型导出、转换和验证三阶段
    实际部署时建议配合TensorRT进行最终优化，对于图像分类等任务可扩展添加预处理层固化。

## dynamic_to_static_use_TorchScript.py（pytorch原生工具，将pt动态图模型转为静态图模型）
    实现动态模型类，包含条件分支等动态特性
    提供两种动态导出方式：trace模式（性能优先）和script模式（保留逻辑）
    静态转换通过固定输入尺寸重新trace实现
    包含完整的模型验证流程
    输出三种模型文件：动态trace版、动态script版和静态版
    运行要求：PyTorch>=1.8.0，无其他外部依赖。转换后的静态模型可部署到LibTorch等推理环境。

## dequantize_model.py (反量化：静态量化PT模型转全精度模型)

    以下是关于PyTorch静态量化模型反量化精度损失的详细分析：

    1. 反量化原理与精度特性

    反量化过程本质上是将低精度整数映射回高精度浮点数的线性变换，其数学表达式为：

    2. 实际精度损失来源

    虽然反量化本身无信息损失，但实际应用中精度损失主要来自以下环节：

    量化阶段‌：原始FP32数据转换为INT8时，四舍五入和截断操作导致的信息丢失（典型损失0.5-3%）‌
    计算累积误差‌：量化模型在INT8计算过程中产生的误差会随网络深度累积‌
    激活值截断‌：ReLU等非线性操作在量化后可能丢失部分激活信息‌
    3. 工业级精度损失范围

    根据实际测试数据：

    对称量化‌：平均精度损失1-2%（如ResNet50在ImageNet上从76.5%降至74.8%）‌
    非对称量化‌：对ReLU6等操作更友好，损失可控制在0.5-1.5%‌
    极端情况‌：当权重分布偏移严重时，损失可能超过5%‌
    4. 精度补偿技术

    为减少反量化后的精度损失，可采用以下方法：

    KL散度校准‌：优化量化参数使分布差异最小化‌
    混合精度训练‌：对敏感层保持FP16精度‌
    QAT（量化感知训练）‌：在训练阶段模拟量化误差‌
    5. 典型场景对比
    量化类型	反量化后精度损失	适用场景
    PTQ对称量化	1-3%	通用CNN任务
    PTQ非对称量化	0.5-2%	含ReLU6的模型
    QAT量化	<1%	高精度需求场景

    建议在关键业务场景中，通过校准数据集验证反量化后的实际精度损失，并优先选择QAT方案以最小化精度影响‌。

## passdequantize_model_use_onnx.py

    实现要点说明：

    模型定义阶段通过QuantStub/DeQuantStub添加量化节点支持
    6
    使用prepare_qat配置量化训练参数，fbgemm后端针对CPU优化
    1
    校准过程模拟实际部署时的激活值统计
    3
    导出时指定opset_version=13确保量化算子兼容性
    4
    动态轴设置支持可变batch推理
    7
    注意事项：

    实际校准时需使用真实数据替代随机数据
    若遇到不支持的算子需替换为ONNX等效实现
    2
    转换后建议使用onnxruntime验证推理一致性


## pass